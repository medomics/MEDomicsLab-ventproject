{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.basics import *\n",
    "from fastai2.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set `data.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['YAML_DATA']=\"/home/turgutluk/Vent_Seg_Project/dev/configs/data.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.environ.get('YAML_DATA', '../data.yaml')) as f: data_config = yaml.load(f.read(), yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'ATLAS_PATH': '/data/public/PICARE_BMETS_Raw_DICOM_Files',\n",
       "  'MR_PATH': '/data/public/PICARE_SEGMENTATION_BRAINVENT_MR_V1',\n",
       "  'CT_PATH': '/data/public/Training_CT_Raw_DICOM_Files',\n",
       "  'MR_TEST2_PATH': '/data/public/Testing_MR_Raw_DICOM_Files',\n",
       "  'CT_TEST2_PATH': '/data/public/Testing_CT_Raw_DICOM_Files'},\n",
       " 'output': {'ATLAS': '/home/turgutluk/data/ventricles_data/atlas',\n",
       "  'MR': '/home/turgutluk/data/ventricles_data/mr',\n",
       "  'CT': '/home/turgutluk/data/ventricles_data/ct'},\n",
       " 'csv_splits': {'ATLAS': '/home/turgutluk/data/ventricles_data/csvs/atlas_splits_df.csv',\n",
       "  'MR': '/home/turgutluk/data/ventricles_data/csvs/mr_splits_df.csv',\n",
       "  'CT': '/home/turgutluk/data/ventricles_data/csvs/ct_splits_df.csv'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Ignore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# data_paths = types.SimpleNamespace(\n",
    "#     ATLAS_OUTPUT=\"/home/turgutluk/data/ventricles_data/atlas\",\n",
    "#     MR_OUTPUT=\"/home/turgutluk/data/ventricles_data/mr\",\n",
    "#     CT_OUTPUT=\"/home/turgutluk/data/ventricles_data/ct\")\n",
    "\n",
    "# #export\n",
    "# csv_paths = types.SimpleNamespace(\n",
    "#     CT_META = '/home/turgutluk/data/ventricles_data/csvs/CT_PATH_META.csv',\n",
    "#     CT_TEST2_META = '/home/turgutluk/data/ventricles_data/csvs/CT_TEST2_PATH_META.csv',\n",
    "#     MR_META = '/home/turgutluk/data/ventricles_data/csvs/MR_PATH_META.csv',\n",
    "#     MR_TEST2_META = '/home/turgutluk/data/ventricles_data/csvs/MR_TEST2_PATH_META.csv'\n",
    "# )\n",
    "\n",
    "# #export\n",
    "# ct_metadf = pd.read_csv(csv_paths.CT_META,low_memory=False)\n",
    "# ct_test2_metadf = pd.read_csv(csv_paths.CT_TEST2_META,low_memory=False)\n",
    "# mr_metadf = pd.read_csv(csv_paths.MR_META,low_memory=False)\n",
    "# mr_test2_metadf = pd.read_csv(csv_paths.MR_TEST2_META,low_memory=False)\n",
    "\n",
    "# #export\n",
    "# val_test_patients = types.SimpleNamespace(\n",
    "# mr_val = {'ANON61382','ANON55375','ANON85534','ANON54218','ANON24182','ANON14135','ANON49037',\n",
    "#           'ANON66932','ANON10465','ANON39801','ANON14447','ANON42229','ANON99458','ANON36946',\n",
    "#           'ANON16732'},\n",
    "# mr_test1 = {'ANON78381','ANON38662','ANON78219','ANON65248','ANON98217','ANON22366', 'ANON53486',\n",
    "#             'ANON80073','ANON93045','ANON26348','ANON72855','ANON60446','ANON28622','ANON60751',\n",
    "#             'ANON41567'},\n",
    "# ct_val = {'ANON85656','ANON24135','ANON45434','ANON53464','ANON50198','ANON86095','ANON47701',\n",
    "#           'ANON21818','ANON13928','ANON45164','ANON57908','ANON10634','ANON37574','ANON13983',\n",
    "#           'ANON39193','ANON52842','ANON83901','ANON34509','ANON14150','ANON70712','ANON36668',\n",
    "#           'ANON86933','ANON69869','ANON55750'},\n",
    "# ct_test1 = {'ANON95021', 'ANON17272', 'ANON45950', 'ANON71219', 'ANON84614', 'ANON22673',\n",
    "#             'ANON65837', 'ANON51808', 'ANON24224'})\n",
    "\n",
    "# #export\n",
    "# # MR train, val, test1 and test2 StudyInstance UIDs\n",
    "# mr_val_suids = np.unique(mr_metadf[mr_metadf.PatientID.isin(val_test_patients.mr_val)].StudyInstanceUID)\n",
    "# mr_test1_suids = np.unique(mr_metadf[mr_metadf.PatientID.isin(val_test_patients.mr_test1)].StudyInstanceUID)\n",
    "# mr_test2_suids = np.unique(mr_test2_metadf.StudyInstanceUID)\n",
    "# mr_train_suids = (np.unique(mr_metadf[~mr_metadf.StudyInstanceUID\n",
    "#                                       .isin(np.concatenate([mr_val_suids, mr_test1_suids]))]\n",
    "#                                       .StudyInstanceUID))\n",
    "\n",
    "# len(mr_train_suids), len(mr_val_suids), len(mr_test1_suids), len(mr_test2_suids)\n",
    "\n",
    "# #export\n",
    "# # CT train, val, test1 and test2 StudyInstance UIDs\n",
    "# ct_val_suids = np.unique(ct_metadf[ct_metadf.PatientID.isin(val_test_patients.ct_val)].StudyInstanceUID)\n",
    "# ct_test1_suids = np.unique(ct_metadf[ct_metadf.PatientID.isin(val_test_patients.ct_test1)].StudyInstanceUID)\n",
    "# ct_test2_suids = np.unique(ct_test2_metadf.StudyInstanceUID)\n",
    "# ct_train_suids = (np.unique(ct_metadf[~ct_metadf.StudyInstanceUID\n",
    "#                                       .isin(np.concatenate([ct_val_suids, ct_test1_suids]))]\n",
    "#                                       .StudyInstanceUID))\n",
    "\n",
    "# len(ct_train_suids), len(ct_val_suids), len(ct_test1_suids), len(ct_test2_suids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Ignore] create mr (train, val, test1, test2) metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = data_paths.MR_OUTPUT\n",
    "\n",
    "# mr_files = get_files(output_path, extensions=['.pt'])\n",
    "\n",
    "# mr_file_suids = np.unique([o.name.split(\"_\")[0] for o in mr_files])\n",
    "\n",
    "# mr_splitsdf = pd.DataFrame({\"StudyInstanceId\":mr_file_suids, \"SplitType\":None})\n",
    "\n",
    "# mr_splitsdf.loc[mr_splitsdf.StudyInstanceId.isin(mr_train_suids), \"SplitType\"] = \"train\"\n",
    "# mr_splitsdf.loc[mr_splitsdf.StudyInstanceId.isin(mr_val_suids), \"SplitType\"] = \"valid\"\n",
    "# mr_splitsdf.loc[mr_splitsdf.StudyInstanceId.isin(mr_test1_suids), \"SplitType\"] = \"test1\"\n",
    "# mr_splitsdf.loc[mr_splitsdf.StudyInstanceId.isin(mr_test2_suids), \"SplitType\"] = \"test2\"\n",
    "\n",
    "# mr_splitsdf.SplitType.value_counts()\n",
    "\n",
    "# mr_splitsdf.head()\n",
    "\n",
    "# mr_splitsdf.to_csv(\"/home/turgutluk/data/ventricles_data/csvs/mr_splits_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Ignore] create ct (train, val, test1, test2) metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = data_paths.CT_OUTPUT\n",
    "\n",
    "# ct_files = get_files(output_path, extensions=['.pt'])\n",
    "\n",
    "# ct_file_suids = np.unique([o.name.split(\"_\")[0] for o in ct_files])\n",
    "\n",
    "# ct_splitsdf = pd.DataFrame({\"StudyInstanceId\":ct_file_suids, \"SplitType\":None})\n",
    "\n",
    "# ct_splitsdf.loc[ct_splitsdf.StudyInstanceId.isin(ct_train_suids), \"SplitType\"] = \"train\"\n",
    "# ct_splitsdf.loc[ct_splitsdf.StudyInstanceId.isin(ct_val_suids), \"SplitType\"] = \"valid\"\n",
    "# ct_splitsdf.loc[ct_splitsdf.StudyInstanceId.isin(ct_test1_suids), \"SplitType\"] = \"test1\"\n",
    "# ct_splitsdf.loc[ct_splitsdf.StudyInstanceId.isin(ct_test2_suids), \"SplitType\"] = \"test2\"\n",
    "\n",
    "# ct_splitsdf.SplitType.value_counts()\n",
    "\n",
    "# ct_splitsdf.head()\n",
    "\n",
    "# ct_splitsdf.to_csv(\"/home/turgutluk/data/ventricles_data/csvs/ct_splits_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Ignore] create atlas metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = data_paths.ATLAS_OUTPUT\n",
    "\n",
    "# atlas_files = get_files(output_path, extensions=['.pt'])\n",
    "\n",
    "# atlas_file_suids = np.unique([o.name.split(\"_\")[0] for o in atlas_files])\n",
    "\n",
    "# atlas_splitsdf = pd.DataFrame({\"StudyInstanceId\":atlas_file_suids, \"SplitType\":\"train\"})\n",
    "\n",
    "# atlas_splitsdf.SplitType.value_counts()\n",
    "\n",
    "# atlas_splitsdf.to_csv(\"/home/turgutluk/data/ventricles_data/csvs/atlas_splits_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MR CT DataSource \n",
    "\n",
    "- notl_brain_mr - [norm. image + brain mask]\n",
    "- notl_brain_ct - [norm. image + brain mask]\n",
    "- notl_ventricle_mr - [norm. skull stripped image + ventricles mask]\n",
    "- notl_ventricle_ct - [norm. skull stripped image + ventricles mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.dicom2tensor import _plot_voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export \n",
    "import yaml\n",
    "with open(os.environ.get('YAML_DATA', '../data.yaml')) as f: data_config = yaml.load(f.read(), yaml.FullLoader)\n",
    "\n",
    "# define input and output paths\n",
    "input_paths = types.SimpleNamespace(\n",
    "    ATLAS_PATH=data_config['input']['ATLAS_PATH'],\n",
    "    MR_PATH=data_config['input']['MR_PATH'],\n",
    "    CT_PATH=data_config['input']['CT_PATH'],\n",
    "    MR_TEST2_PATH=data_config['input']['MR_TEST2_PATH'],\n",
    "    CT_TEST2_PATH=data_config['input']['CT_TEST2_PATH'],\n",
    ")\n",
    "\n",
    "output_paths = types.SimpleNamespace(\n",
    "    ATLAS=data_config['output']['ATLAS'],\n",
    "    MR=data_config['output']['MR'],\n",
    "    CT=data_config['output']['CT'])\n",
    "\n",
    "csv_split_paths = types.SimpleNamespace(\n",
    "    ATLAS=data_config['csv_splits']['ATLAS'],\n",
    "    MR=data_config['csv_splits']['MR'],\n",
    "    CT=data_config['csv_splits']['CT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tfm_image_pt(o, data_path): return data_path/(o + \"_image_normalized.pt\")\n",
    "def tfm_brain_mask_pt(o, data_path): return data_path/(o + \"_brain_mask.pt\")\n",
    "def tfm_skull_stripped_image_pt(o, data_path): return data_path/(o + \"_skull_stripped_image_normalized.pt\")\n",
    "def tfm_ventricles_mask_pt(o, data_path): return data_path/(o + \"_ventricles_mask.pt\")\n",
    "def unsqz(x): return x[None,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_mr_ct_dsource(data_path, csv_splits_path, tfm_pt_x, tfm_pt_y):\n",
    "    \"\"\"\n",
    "    data_path: directory of tensor files \n",
    "    csv_splits_path: csv path for split info\n",
    "    tfm_pt_x: tfm_image_pt or tfm_skull_stripped_image_pt\n",
    "    tfm_pt_y: tfm_brain_mask_pt or tfm_ventricles_mask_pt\n",
    "    \"\"\"\n",
    "    data_path = Path(data_path)\n",
    "    splits_df = pd.read_csv(csv_splits_path)\n",
    "    suids = splits_df['StudyInstanceId'].values\n",
    "    \n",
    "    tfmx = [partial(tfm_pt_x, data_path=data_path), torch.load, unsqz]\n",
    "    tfmy = [partial(tfm_pt_y, data_path=data_path), torch.load]\n",
    "    \n",
    "    train_suids = splits_df.loc[splits_df.SplitType == \"train\", \"StudyInstanceId\"].values # subset 0\n",
    "    valid_suids = splits_df.loc[splits_df.SplitType == \"valid\", \"StudyInstanceId\"].values # subset 1\n",
    "    test1_suids = splits_df.loc[splits_df.SplitType == \"test1\", \"StudyInstanceId\"].values # subset 2\n",
    "    test2_suids = splits_df.loc[splits_df.SplitType == \"test2\", \"StudyInstanceId\"].values # subset 3\n",
    "    \n",
    "    train_idxs = [idx for idx, suid in enumerate(suids) if suid in train_suids] \n",
    "    valid_idxs = [idx for idx, suid in enumerate(suids) if suid in valid_suids] \n",
    "    test1_idxs = [idx for idx, suid in enumerate(suids) if suid in test1_suids] \n",
    "    test2_idxs = [idx for idx, suid in enumerate(suids) if suid in test2_suids] \n",
    "    \n",
    "    dsource = DataSource(suids, tfms=[tfmx, tfmy], splits=[train_idxs, valid_idxs, test1_idxs, test2_idxs])\n",
    "    return dsource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "get_notl_brain_mr_dsource = partial(create_mr_ct_dsource, output_paths.MR,\n",
    "                                             csv_split_paths.MR,\n",
    "                                             tfm_image_pt,\n",
    "                                             tfm_brain_mask_pt)\n",
    "\n",
    "get_notl_brain_ct_dsource = partial(create_mr_ct_dsource, output_paths.CT,\n",
    "                                             csv_split_paths.CT,\n",
    "                                             tfm_image_pt,\n",
    "                                             tfm_brain_mask_pt)\n",
    "\n",
    "get_notl_ventricle_mr_dsource = partial(create_mr_ct_dsource, output_paths.MR,\n",
    "                                                 csv_split_paths.MR,\n",
    "                                                 tfm_skull_stripped_image_pt,\n",
    "                                                 tfm_ventricles_mask_pt)\n",
    "\n",
    "get_notl_ventricle_ct_dsource = partial(create_mr_ct_dsource, output_paths.CT,\n",
    "                                                 csv_split_paths.CT,\n",
    "                                                 tfm_skull_stripped_image_pt,\n",
    "                                                 tfm_ventricles_mask_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "datasource_dict = {}\n",
    "datasource_dict['notl_brain_mr'] = get_notl_brain_mr_dsource\n",
    "datasource_dict['notl_brain_ct'] = get_notl_brain_ct_dsource\n",
    "datasource_dict['notl_ventricle_mr'] = get_notl_ventricle_mr_dsource\n",
    "datasource_dict['notl_ventricle_ct']  = get_notl_ventricle_ct_dsource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsource = datasource_dict['notl_brain_mr'](); len(dsource.splits) # train, valid, test1, test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlas DataSource\n",
    "\n",
    "- atlas_ventricle_mr - [norm. skull stripped image + ventricles mask]\n",
    "- atlas_brain_mr - [norm. image + brain mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def atlas_tfm_image_pt(o): return o.parent/(o.name + \"_image_normalized.pt\")\n",
    "def atlas_tfm_brain_mask_pt(o): return o.parent/(o.name + \"_brain_mask.pt\")\n",
    "def atlas_tfm_skull_stripped_image_pt(o): return o.parent/(o.name + \"_skull_stripped_image_normalized.pt\")\n",
    "def atlas_tfm_ventricles_mask_pt(o): return o.parent/(o.name + \"_ventricles_mask.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_atlas_dsource(atlas_path, mr_path, atlas_splits_path, mr_splits_path, tfm_pt_x, tfm_pt_y):\n",
    "    \"\"\"\n",
    " \n",
    "    tfm_pt_x: tfm_image_pt or tfm_skull_stripped_image_pt\n",
    "    tfm_pt_y: tfm_brain_mask_pt or tfm_ventricles_mask_pt\n",
    "    \"\"\"\n",
    "    atlas_path = Path(atlas_path)\n",
    "    mr_path = Path(mr_path)\n",
    "    atlas_splits_df = pd.read_csv(atlas_splits_path)\n",
    "    mr_splits_df = pd.read_csv(mr_splits_path)\n",
    "    \n",
    "    tfmx = [tfm_pt_x, torch.load, unsqz]\n",
    "    tfmy = [tfm_pt_y, torch.load]\n",
    "    \n",
    "    train_suids = atlas_splits_df.loc[atlas_splits_df.SplitType == \"train\", \"StudyInstanceId\"].values # subset 0\n",
    "    valid_suids = mr_splits_df.loc[mr_splits_df.SplitType == \"valid\", \"StudyInstanceId\"].values # subset 1\n",
    "    \n",
    "    train_items, valid_items = [atlas_path/o for o in train_suids], [mr_path/o for o in valid_suids]\n",
    "    items = train_items + valid_items\n",
    "    train_idxs = np.arange(len(train_items))\n",
    "    valid_idxs = len(train_idxs) + np.arange(len(valid_items))\n",
    "\n",
    "    dsource = DataSource(items, tfms=[tfmx, tfmy], splits=[train_idxs, valid_idxs])\n",
    "    return dsource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "get_atlas_brain_mr_dsource = partial(create_atlas_dsource, output_paths.ATLAS,\n",
    "                                                  output_paths.MR,\n",
    "                                                  csv_split_paths.ATLAS,\n",
    "                                                  csv_split_paths.MR,\n",
    "                                                  atlas_tfm_image_pt,\n",
    "                                                  atlas_tfm_brain_mask_pt)\n",
    "\n",
    "get_atlas_ventricle_mr_dsource = partial(create_atlas_dsource, output_paths.ATLAS,\n",
    "                                                  output_paths.MR,\n",
    "                                                  csv_split_paths.ATLAS,\n",
    "                                                  csv_split_paths.MR,\n",
    "                                                  atlas_tfm_skull_stripped_image_pt,\n",
    "                                                  atlas_tfm_ventricles_mask_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "datasource_dict['atlas_brain_mr'] = get_atlas_ventricle_mr_dsource\n",
    "datasource_dict['atlas_ventricle_mr'] = get_atlas_brain_mr_dsource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsource = datasource_dict['atlas_ventricle_mr'](); len(dsource.splits) # only train and valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 2) datasource.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from local.notebook.export import notebook2script\n",
    "notebook2script(\"2) datasource.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai_dev]",
   "language": "python",
   "name": "conda-env-fastai_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

#AUTOGENERATED! DO NOT EDIT! File to edit: dev/1a) dicom to tensor.ipynb (unless otherwise specified).

__all__ = ['create_voxel_mask', 'collect_study_datasets', 'separate_instance_datasets', 'ROI', 'resample_voxel',
           'center_crop_pad', 'create_and_save_img_mask', 'save_study', 'input_paths', 'output_paths', 'main']

#Cell
from fastai2.medical.imaging_roi import *
from fastai2.medical.imaging import dicom_windows
from fastai2 import *
from fastai2.torch_core import *
from fastai2.core import *
from fastai2.basics import *

#Cell
def create_voxel_mask(image_ds_list, refid2masks):
    voxel_mask = []
    for img_ds in image_ds_list:
        refid = img_ds[dicom_tags.sop_instance_uid].value
        if refid in refid2masks: voxel_mask += [refid2masks[refid]]
        else: voxel_mask += [torch.zeros(img_ds.shape, dtype=torch.uint8)]
    voxel_mask = torch.stack(voxel_mask); voxel_mask.shape
    return voxel_mask

#Cell
def collect_study_datasets(dcm_datasets):
    "collect study datasets by study instance uid key"
    study_datasets = defaultdict(list)
    for o in dcm_datasets:
        if o.modality == dicom_modality.rtstruct:
            study_datasets[o[dicom_tags.study_instance_uid].value].append(o)
        elif o.modality in [dicom_modality.ct, dicom_modality.mr]:
            study_datasets[o[dicom_tags.study_instance_uid].value].append(o)
        else: raise Exception(f"Unknown modality: {o.modality} in DcmDataset")
    return study_datasets

#Cell
def separate_instance_datasets(instance_datasets):
    "separate instance datasets into RTSTRUCT and image"
    struct_ds_list, image_ds_list = [],[]
    for o in instance_datasets:
        if o.modality == dicom_modality.rtstruct:
            struct_ds_list.append(o)
        elif o.modality in [dicom_modality.ct, dicom_modality.mr]:
            image_ds_list.append(o)
    # pick first as struct ds
    struct_ds = struct_ds_list[0]
    return (struct_ds, image_ds_list)

#Cell
ROI = types.SimpleNamespace(brain="Brain", ventricles="Ventricles")

#Cell
def resample_voxel(x, scale_factor):
    "resamples 3D tensor x with scale_factor (z,y,x)"
    return F.interpolate(x[None,None,...].float(), scale_factor=scale_factor)[0,0]

#Cell
def center_crop_pad(x, targ_sz=(128,256,256)):
    "do center crop or pad to transform to targ_sz"
    x = x.clone()
    targ_sz = array(targ_sz)
    size = array(x.shape)
    cnt = size//2
    z1,x1,y1,z2,x2,y2 = (*cnt - targ_sz//2, *cnt + targ_sz//2)
    if (x1 > 0) and (y1 > 0):       x = x[:,x1:x2,y1:y2]
    elif (x1 > 0) and (y1 <= 0):    x = F.pad(x[:,x1:x2,:], (-y1,-y1))
    elif (x1 <= 0) and (y1 > 0):    x = F.pad(x[:,:,y1:y2], (0,0,-x1,-x1))
    else:                           x = F.pad(x, (-y1,-y1,-x1,-x1))

    if z1 > 0: x = x[z1:z2]
    else: x = F.pad(x, (0,0,0,0,-z1,-z1))

    if list(x.shape) != list(targ_sz):
        resz, resy, resx = array(x.shape) - array(targ_sz)
        if resx == 1: x = x[:,:,1:]
        elif resx == -1: x = F.pad(x, (0,1))

        if resy == 1: x = x[:,1:,:]
        elif resy == -1: x = F.pad(x, (0,0,0,1))

        if resz == 1: x = x[1:,:,:]
        elif resz == -1: x = F.pad(x, (0,0,0,0,0,1))

    try:
        assert list(x.shape) == list(targ_sz)
    except:
        raise Exception(x.shape)
    finally:
        return x

#Cell
def create_and_save_img_mask(instance_datasets, output_path, resample_to=(1,1,3)):
    "save image and masks of a single study instance"
    struct_ds, image_ds_list = separate_instance_datasets(instance_datasets)
    study_instance_uid = struct_ds[dicom_tags.study_instance_uid].value
    if (ROI.brain not in struct_ds.roi_names) and (ROI.ventricles not in struct_ds.roi_names): return
    brain_contour_refdict = struct_ds.contour_refdict(ROI.brain)
    ventricles_contour_refdict = struct_ds.contour_refdict(ROI.ventricles)

    # image voxel
    refid2img_ds = {img_ds[dicom_tags.sop_instance_uid].value:img_ds for img_ds in image_ds_list}
    image_ds_list = sorted(image_ds_list, key=lambda o: int(o['InstanceNumber'].value))
    voxel_image = torch.stack([img_ds.windowed(*dicom_windows.brain) if img_ds.modality == dicom_modality.ct
                               else img_ds.pixels for img_ds in image_ds_list])

    # brain mask voxel
    refid2masks = {}
    for refid, contourdata in brain_contour_refdict.items():
        ref_ds = refid2img_ds[refid]
        refid2masks[refid] = tensor(sum([ref_ds.contourdata2mask(o) for o in contourdata]).astype(np.uint8))
    brain_voxel_mask = create_voxel_mask(image_ds_list, refid2masks)

    # ventricles mask voxel
    refid2masks = {}
    for refid, contourdata in ventricles_contour_refdict.items():
        ref_ds = refid2img_ds[refid]
        refid2masks[refid] = tensor(sum([ref_ds.contourdata2mask(o) for o in contourdata]).astype(np.uint8))
    ventricles_voxel_mask = create_voxel_mask(image_ds_list, refid2masks)

    # resample
    if resample_to is not None:
        image_ds = image_ds_list[0] # pick one image dataset for metadata
        scale_factor = image_ds.spacings[::-1] # z,y,x
        voxel_image = resample_voxel(voxel_image, scale_factor)
        brain_voxel_mask = resample_voxel(brain_voxel_mask, scale_factor).byte()
        ventricles_voxel_mask = resample_voxel(ventricles_voxel_mask, scale_factor).byte()

    # save image and masks by study instance uid
    torch.save(voxel_image, output_path/f"{study_instance_uid}_image.pt")
    torch.save(brain_voxel_mask, output_path/f"{study_instance_uid}_brain_mask.pt")
    torch.save(ventricles_voxel_mask, output_path/f"{study_instance_uid}_ventricles_mask.pt")

#Cell
def save_study(study, output_path, **kwargs):
    try:
        dcm_files = get_files(study, extensions=['.dcm'])
        dcm_datasets = (o.dcmread() for o in dcm_files)
        study_datasets = collect_study_datasets(dcm_datasets)
        study_datasets = list((study_datasets).values())
        # save each instance in this study
        f = partial(create_and_save_img_mask, output_path=output_path, **kwargs)
        for o in study_datasets: f(o)

    except Exception as e:
        print(f"{e}, study: {study}")

#Cell
def _crop_pad_save(o, targ_sz):
    try:
        x = torch.load(o)
        x = center_crop_pad(x, targ_sz)
        torch.save(x, o)
    except: pass

#Cell
import yaml
with open(os.environ.get('YAML_DATA', '../data.yaml')) as f: data_config = yaml.load(f.read(), yaml.FullLoader)

# define input and output paths
input_paths = types.SimpleNamespace(
    ATLAS_PATH=data_config['input']['ATLAS_PATH'],
    MR_PATH=data_config['input']['MR_PATH'],
    CT_PATH=data_config['input']['CT_PATH'],
    MR_TEST2_PATH=data_config['input']['MR_TEST2_PATH'],
    CT_TEST2_PATH=data_config['input']['CT_TEST2_PATH'],
)

output_paths = types.SimpleNamespace(
    ATLAS=data_config['output']['ATLAS'],
    MR=data_config['output']['MR'],
    CT=data_config['output']['CT'])

#Cell
from time import perf_counter
@call_parse
def main(input_path:Param("Data to prepare", str),
         output_path:Param("Data to prepare", str),
         resample_to:Param("Resample dimensions in mm", tuple)=(1,1,3),
         targ_sz:Param("Final crop pad dimensions", tuple)=(128,256,256)
        ):
    "Read DICOM from input_path and save image-mask tensors to output_path"

    start = perf_counter()

    # get input and output paths
    input_path, output_path = input_paths.__dict__[input_path], output_paths.__dict__[output_path]
    input_path, output_path = Path(input_path), Path(output_path)
    os.makedirs(output_path, exist_ok=True)
    print(f"reading from {str(input_path)}\nwriting to {str(output_path)}")

    # read, interpolate
    print("Read, create, interpolate and save")
    studies = input_path.ls()
    f = partial(save_study, output_path=output_path, resample_to=resample_to)
    parallel(f, studies, n_workers=defaults.cpus//4)

    # crop - pad and save
    print("Read, crop-pad and save")
    files = get_files(output_path, extensions=['.pt'])
    f = partial(_crop_pad_save, targ_sz=targ_sz)
    parallel(f, files, n_workers=defaults.cpus//4)

    end = perf_counter()
    print(f"Total time taken {end-start} seconds")

#Cell
def _plot_voxel(voxel):
    n = int(np.ceil(np.sqrt(len(voxel))))
    fig,axes = plt.subplots(n,n,figsize=(4*n,4*n))
    for i,(arr,ax) in enumerate(zip(voxel,axes.flatten())):
        ax.imshow(arr); ax.set_title(str(i)); ax.set_xticks([]); ax.set_yticks([])